---
layout: post
title: AI^2 Forum May 2023
tags:
- AI_squared
---

Dr. Kieran Zucker spoke at the AI^2 forum about the challenges of implementing AI in healthcare. Despite the widespread belief in AI's potential to revolutionize healthcare, there are several barriers preventing its effective use in clinical settings. The main takeaway points from the talk are as follows:

1. __Design thinking__: When developing AI tools for healthcare, it is crucial to consider the key stakeholders and their needs. Identifying the individuals who will use the product is essential for successful implementation.

2. __Stakeholders__: There are seven groups of stakeholders we need to consider when integrating AI into clinical practice:

* _Hospitals_: Limited resources and budget constraints hinder the adoption of AI technologies in healthcare settings. Skepticism towards tools that are marketed as time and cost savers further contributes to the reluctance to invest in AI.

* _Primary care_: Pitching AI to primary care requires addressing the cost-saving potential of the technology. Integrated care systems (ICSs) represent the care requirements in each region and must be convinced of the financial benefits.

* _Clinicians_: Change is slow in healthcare, even when the benefits of AI are proven. Doctors often have a limited perspective on the hospital system, and their workload may lead them to over-rely on AI, raising questions of accountability if something goes wrong.

* _Computer scientists_: Developers sometimes focus on creating tools for non-existent problems, lacking practical utility. Understanding and assessing datasets are crucial, as models may not work effectively across different hospitals or clinics. It is essential to define the limitations of AI tools and address discrepancies when multiple tests or clinicians disagree.

* _Companies_: Companies may withdraw from AI deals if they do not find them profitable enough, wasting resources spent on clinical trials. Overselling capabilities can also lead to disappointment. Improved standards and regulations are needed for AI medical devices.

* _Governments_: Decision-makers and regulators often lack understanding of AI but are responsible for setting standards and recommendations in the healthcare sector.

* _Patients_: Patient perspectives are often overlooked, even though they are the ones most affected by AI in healthcare. The lack of explainability in AI models leads to poor understanding and trust among patients. Research and consideration of patients' needs are essential.

__Key messages__:

* Prioritize data over methods, as models can be adjusted easily while ensuring data generalizability for the specific problem at hand.

* Understand stakeholders and employ design thinking strategies to gain traction and facilitate translation of AI into healthcare.

* Begin with a problem-oriented approach rather than starting with AI methods.

* Economic and qualitative evidence can help support the implementation of AI in healthcare.

We also discussed what we would tell ourselves and what advice we would give to our former selves as PhD students. In case you missed it - we created a virtual post-it board containing all the advice:

![PhD Post-Its](../images/PhD_advice.png)
